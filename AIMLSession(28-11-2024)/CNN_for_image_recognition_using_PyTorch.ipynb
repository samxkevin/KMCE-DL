{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLGfkl8LsDj2"
   },
   "source": [
    "\n",
    "**Building a simple Convolutional Neural Network (CNN) for image recognition using PyTorch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iF44MgQIuLW7",
    "outputId": "b327a2ba-9796-47d9-b226-b14272f12747"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "#1. Installing Required Libraries\n",
    "# Make sure PyTorch is installed. Install it using:\n",
    "\n",
    "#pip install torch torchvision matplotlib\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UwVK-HpKuSRJ"
   },
   "outputs": [],
   "source": [
    "#2. Importing Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f4NK9_CuUOO"
   },
   "outputs": [],
   "source": [
    "#3. Loading and Preprocessing the Data\n",
    "# Key Functions:\n",
    "\n",
    "#transforms.ToTensor(): Converts images to PyTorch tensors.\n",
    "\n",
    "#transforms.Normalize((mean,), (std,)): Normalizes image pixel values.\n",
    "\n",
    "#DataLoader: Handles batching, shuffling, and parallel data loading.\n",
    "\n",
    "\n",
    "\n",
    "# Transform to normalize and convert images to tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1], we do this for uniformity purposes\n",
    "])\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)#must be completely different from test data...\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)#generally we have validation datasets also but lets go on to it later...\n",
    "\n",
    "# Data loaders for batching\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)#data loader gives the data to the neural network in batch format\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sA9yopSutAs"
   },
   "outputs": [],
   "source": [
    "# 4. Defining the CNN Model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()#flexiblity to the user\n",
    "        # Convolutional layer, Channel means color monochrome so one, weights 32*9 - parameters\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)#padding is done to avoid giving less attention to the pixels in the \"edges\" of the image. output size: [(W-K+2P)/s]+1 \n",
    "        # Max-pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)#image will condensed to half of the size of earlier feature maps\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 128)#one layer 32*14*14*128, completely 32*14*14*128+32*9 - parameters\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):# x is an array an image... 28*28\n",
    "\n",
    "        x = torch.relu(self.conv1(x))  # Apply ReLU after convolution, x is 64*28*28 (since we have 64 batches)\n",
    "        x = self.pool(x)  # Apply max pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten the feature map(2d and 64 is retained)\n",
    "        x = torch.relu(self.fc1(x))  # Fully connected layer with ReLU\n",
    "        x = self.fc2(x)  # Output layer (no activation; handled by loss function), dimensions become 64*10\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Huv8ifxZ0Dxs",
    "outputId": "e69a22b8-2e25-45ae-eed9-8643fa4a76ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.1154, -0.3168, -0.1498],\n",
      "          [-0.1384, -0.2459,  0.0334],\n",
      "          [-0.1107, -0.0815,  0.1763]]],\n",
      "\n",
      "\n",
      "        [[[-0.2970,  0.1310, -0.0562],\n",
      "          [-0.0825, -0.1250, -0.2719],\n",
      "          [-0.1645, -0.1145,  0.0631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0459,  0.3112, -0.1478],\n",
      "          [ 0.0198, -0.3284, -0.2580],\n",
      "          [-0.0107, -0.1478, -0.3242]]],\n",
      "\n",
      "\n",
      "        [[[-0.0050, -0.2627,  0.1337],\n",
      "          [-0.2508, -0.2026, -0.0050],\n",
      "          [ 0.2191,  0.1001, -0.0049]]],\n",
      "\n",
      "\n",
      "        [[[-0.3072, -0.1306, -0.2196],\n",
      "          [-0.2684, -0.2767,  0.0391],\n",
      "          [ 0.2396,  0.0653,  0.3195]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2810, -0.0360, -0.0781],\n",
      "          [ 0.1951, -0.1319,  0.2239],\n",
      "          [-0.2029, -0.3299,  0.1391]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0968,  0.0011, -0.1338],\n",
      "          [-0.0590,  0.2167, -0.1396],\n",
      "          [ 0.0913,  0.1868,  0.1250]]],\n",
      "\n",
      "\n",
      "        [[[-0.3135, -0.0523,  0.3244],\n",
      "          [ 0.0432,  0.1718, -0.0651],\n",
      "          [-0.2439,  0.1818, -0.0424]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3075, -0.3307, -0.0868],\n",
      "          [ 0.3084, -0.1053,  0.0849],\n",
      "          [ 0.2081, -0.2702, -0.2495]]],\n",
      "\n",
      "\n",
      "        [[[-0.1015,  0.1432, -0.3130],\n",
      "          [-0.1354,  0.1005,  0.2737],\n",
      "          [-0.3139,  0.0719, -0.2523]]],\n",
      "\n",
      "\n",
      "        [[[-0.1419, -0.3212, -0.1045],\n",
      "          [-0.2833, -0.1199, -0.2126],\n",
      "          [-0.1816, -0.0595,  0.1358]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0620, -0.3202, -0.0452],\n",
      "          [ 0.0804,  0.1703,  0.0109],\n",
      "          [ 0.1655,  0.0207, -0.2119]]],\n",
      "\n",
      "\n",
      "        [[[-0.0654,  0.1380,  0.3017],\n",
      "          [-0.1028, -0.1014,  0.0161],\n",
      "          [ 0.1197,  0.0353,  0.2187]]],\n",
      "\n",
      "\n",
      "        [[[-0.2106,  0.2669, -0.0137],\n",
      "          [ 0.1903, -0.3266, -0.2172],\n",
      "          [-0.2991,  0.3180, -0.3082]]],\n",
      "\n",
      "\n",
      "        [[[-0.2679, -0.0289,  0.0075],\n",
      "          [-0.3317,  0.3030, -0.0732],\n",
      "          [ 0.1274, -0.3217, -0.0687]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2403,  0.0055,  0.0091],\n",
      "          [ 0.2150, -0.1288, -0.2154],\n",
      "          [ 0.2872,  0.0526, -0.0961]]],\n",
      "\n",
      "\n",
      "        [[[-0.2643, -0.0819, -0.2339],\n",
      "          [ 0.2269,  0.1215, -0.0124],\n",
      "          [-0.1800,  0.2258, -0.0713]]],\n",
      "\n",
      "\n",
      "        [[[-0.0610,  0.2835,  0.2896],\n",
      "          [-0.0867,  0.1796, -0.3165],\n",
      "          [ 0.2206, -0.1511,  0.1313]]],\n",
      "\n",
      "\n",
      "        [[[-0.3180,  0.0615,  0.2584],\n",
      "          [ 0.2241,  0.2502, -0.1442],\n",
      "          [ 0.2836,  0.1439,  0.0918]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2155, -0.0447, -0.2130],\n",
      "          [-0.3227, -0.1375,  0.2740],\n",
      "          [ 0.0837, -0.0196,  0.1113]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2820,  0.1417, -0.3243],\n",
      "          [ 0.1464,  0.2205, -0.3088],\n",
      "          [-0.1957, -0.1227, -0.0351]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0279, -0.0907, -0.2407],\n",
      "          [-0.2292, -0.1499,  0.1848],\n",
      "          [-0.2985,  0.1935,  0.0707]]],\n",
      "\n",
      "\n",
      "        [[[-0.1101,  0.0051, -0.1817],\n",
      "          [-0.3068,  0.2666,  0.2830],\n",
      "          [-0.1826, -0.2591, -0.0550]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2680, -0.0947, -0.0723],\n",
      "          [-0.2027,  0.1199, -0.1722],\n",
      "          [-0.0505,  0.3050,  0.1038]]],\n",
      "\n",
      "\n",
      "        [[[-0.2490,  0.2645, -0.2297],\n",
      "          [ 0.0370, -0.2513, -0.3318],\n",
      "          [-0.1110, -0.2867,  0.0291]]],\n",
      "\n",
      "\n",
      "        [[[-0.2455, -0.2736,  0.2727],\n",
      "          [ 0.2082,  0.2735, -0.1167],\n",
      "          [ 0.0309, -0.2012, -0.0084]]],\n",
      "\n",
      "\n",
      "        [[[-0.1945,  0.2601,  0.2786],\n",
      "          [ 0.3089, -0.0934, -0.1580],\n",
      "          [-0.1165,  0.3122, -0.0667]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2053,  0.0328, -0.1014],\n",
      "          [-0.1005, -0.1396, -0.1280],\n",
      "          [-0.2840,  0.2385,  0.0570]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1113,  0.1683,  0.1686],\n",
      "          [-0.1072,  0.1938, -0.0416],\n",
      "          [-0.2583, -0.1988,  0.3271]]],\n",
      "\n",
      "\n",
      "        [[[-0.1807, -0.0933,  0.0967],\n",
      "          [-0.1843, -0.1744,  0.3268],\n",
      "          [-0.3058, -0.2060, -0.2852]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2513, -0.3296, -0.2569],\n",
      "          [-0.3049,  0.2691, -0.1597],\n",
      "          [ 0.0332, -0.0321,  0.0562]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2205,  0.0868, -0.1441],\n",
      "          [-0.1592, -0.2644,  0.1383],\n",
      "          [-0.1565, -0.1130, -0.0318]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0609,  0.2871,  0.1976,  0.1025,  0.2235, -0.2587, -0.1764, -0.2240,\n",
      "        -0.0116, -0.3052, -0.2859,  0.0093, -0.0944,  0.1515, -0.1165,  0.2061,\n",
      "         0.2997,  0.2522,  0.0281,  0.1448, -0.1984, -0.1338,  0.3208, -0.2979,\n",
      "         0.1704,  0.3221, -0.2566, -0.2034,  0.0249, -0.3231,  0.1267,  0.2478],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-6.2954e-03, -1.1926e-02, -4.0490e-03,  ...,  9.1993e-03,\n",
      "          4.6268e-03, -7.9180e-03],\n",
      "        [ 7.6847e-03, -1.1097e-02, -1.1154e-02,  ...,  7.0036e-04,\n",
      "          2.5670e-05,  7.0423e-03],\n",
      "        [ 2.9629e-03,  7.6711e-03,  8.5860e-03,  ...,  3.5813e-03,\n",
      "          1.0210e-02,  8.8936e-03],\n",
      "        ...,\n",
      "        [ 1.2598e-02, -9.8912e-03,  6.1761e-03,  ..., -5.8390e-03,\n",
      "          9.6857e-03, -3.7106e-03],\n",
      "        [ 1.1552e-02, -4.4808e-03, -7.9844e-03,  ...,  5.0697e-04,\n",
      "          4.3371e-04, -1.2634e-03],\n",
      "        [-8.9914e-03,  8.7787e-03,  5.6831e-03,  ...,  4.2353e-03,\n",
      "         -1.1534e-02,  2.0237e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([-9.7047e-03,  1.0790e-02, -1.1395e-02, -7.7870e-03,  1.1254e-02,\n",
      "        -6.8369e-03, -3.4665e-03, -2.2431e-03, -6.6823e-03, -2.8838e-03,\n",
      "         5.5661e-03,  9.0932e-06,  1.2214e-03, -1.0792e-02,  1.2584e-02,\n",
      "        -8.2005e-03,  6.3335e-03,  3.7472e-03,  2.8553e-03, -2.2535e-03,\n",
      "        -1.0245e-02, -6.2038e-03, -6.2650e-03, -6.6128e-04,  4.2758e-03,\n",
      "        -2.2687e-03, -7.6969e-03, -8.7439e-03, -8.0314e-03,  1.2425e-02,\n",
      "        -1.1887e-03,  4.4061e-03,  5.2167e-03,  9.9637e-03, -9.8160e-03,\n",
      "         1.1732e-02, -1.8940e-03, -4.1310e-03, -4.9476e-03,  8.2259e-03,\n",
      "        -8.4616e-03,  1.0443e-02, -7.2825e-03,  2.8061e-03, -1.0076e-02,\n",
      "        -5.1358e-03, -1.5978e-03,  6.9319e-03, -1.2543e-02,  7.2819e-03,\n",
      "         5.1446e-03, -1.1175e-02,  5.4570e-03, -1.2043e-02, -4.6860e-03,\n",
      "         2.9977e-03, -2.0809e-03,  1.1570e-02,  1.0634e-02, -9.3377e-03,\n",
      "         8.8719e-04,  8.8915e-03, -5.5113e-03, -5.1990e-03, -7.7528e-03,\n",
      "         3.3776e-03, -4.0389e-03, -1.2601e-02, -1.6748e-03, -1.1889e-02,\n",
      "         1.7829e-03, -6.7741e-03,  1.1798e-02,  5.4742e-03, -7.6850e-03,\n",
      "         2.4044e-03, -4.3232e-03, -3.9257e-03,  5.2670e-03, -4.2716e-03,\n",
      "         2.7719e-03,  1.0856e-02, -5.1720e-03, -2.2582e-03, -5.9572e-03,\n",
      "        -2.6401e-03, -8.3023e-03, -1.0340e-02,  9.7836e-04,  4.6149e-03,\n",
      "        -7.5879e-03,  1.1542e-02,  3.1781e-03, -1.0636e-02, -5.2958e-04,\n",
      "        -3.8816e-03, -1.1634e-02, -5.9062e-04,  4.8361e-03, -5.7596e-03,\n",
      "        -1.1151e-02, -1.3579e-03, -6.9768e-03, -8.2561e-03, -1.3348e-03,\n",
      "         1.1010e-02,  1.5955e-03, -2.1081e-03,  1.2218e-02,  3.8431e-03,\n",
      "        -1.0252e-02,  8.8821e-03,  1.0383e-02, -8.2425e-03, -7.9404e-03,\n",
      "         8.2876e-03,  9.6143e-03,  1.1201e-02,  6.6831e-03,  1.1681e-02,\n",
      "        -6.9890e-03,  6.5923e-03, -9.5066e-03,  1.4291e-03,  1.0028e-02,\n",
      "         1.0750e-02,  8.6963e-03, -6.7254e-03], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0175,  0.0598,  0.0618,  ..., -0.0359, -0.0785,  0.0010],\n",
      "        [ 0.0879,  0.0876, -0.0796,  ...,  0.0305, -0.0266, -0.0333],\n",
      "        [ 0.0481,  0.0390, -0.0090,  ..., -0.0376,  0.0320,  0.0632],\n",
      "        ...,\n",
      "        [ 0.0052,  0.0199, -0.0719,  ...,  0.0648, -0.0538, -0.0106],\n",
      "        [ 0.0108, -0.0773, -0.0791,  ..., -0.0844,  0.0766, -0.0323],\n",
      "        [ 0.0271,  0.0453, -0.0034,  ..., -0.0529,  0.0530, -0.0017]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0301,  0.0639,  0.0383, -0.0064, -0.0639,  0.0297, -0.0267,  0.0516,\n",
      "        -0.0636, -0.0140], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "#check  model has trainable parameters by printing them:\n",
    "model = CNN().to(device)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjMK5CUDv-a_"
   },
   "source": [
    "** #5. Understanding Each Component\n",
    "\n",
    "# a. nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "in_channels: Number of input channels (1 for grayscale images).\n",
    "\n",
    "out_channels: Number of filters (32 in this case).\n",
    "\n",
    "kernel_size: Size of the filter (3x3 here).\n",
    "\n",
    "stride: Steps the filter moves (1 here).\n",
    "\n",
    "padding: Adds padding around the image to maintain dimensions.\n",
    "\n",
    "\n",
    "# b. nn.MaxPool2d(kernel_size, stride)\n",
    "\n",
    "Reduces spatial dimensions by taking the maximum value in a region.\n",
    "\n",
    "\n",
    "# c. nn.Linear(in_features, out_features)\n",
    "\n",
    "Fully connected layers where each input node is connected to every output node.\n",
    "\n",
    "\n",
    "# d. torch.relu(x)\n",
    "\n",
    "Applies the ReLU activation function, setting all negative values to 0.\n",
    "\n",
    "\n",
    "# e. x.view(x.size(0), -1)\n",
    "\n",
    "Flattens the output tensor to prepare it for the fully connected layer.\n",
    "\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M4TdSPnwfvI"
   },
   "outputs": [],
   "source": [
    "#6. Initializing the Model, Loss Function, and Optimizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')#compute unified device architecture\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for classification - many value(cross entropy loss is used in this case), regression- one value(mse is used mean square error)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression can be written in LaTeX as:\n",
    "\n",
    "$$\n",
    "-\\frac{1}{n} \\sum \\left( y_{\\text{actual}} \\cdot \\log(y_{\\text{pred}}) \\right)\n",
    "$$\n",
    "\n",
    "This represents the formula for the cross-entropy loss, often used in classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujAmgNfC1Ggc",
    "outputId": "29da1e23-54e0-4916-892b-cd3dd81e1bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2057\n",
      "Epoch [2/5], Loss: 0.0699\n",
      "Epoch [3/5], Loss: 0.0467\n",
      "Epoch [4/5], Loss: 0.0352\n",
      "Epoch [5/5], Loss: 0.0262\n"
     ]
    }
   ],
   "source": [
    "# 7. Training the Model\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode, ANN complete utility in one line.\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)# label ground truth\n",
    "\n",
    "        optimizer.zero_grad()  # Zero out gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBayiX552iHI",
    "outputId": "e9592906-bc28-4ae2-b5e2-7fee354ad3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.49%\n"
     ]
    }
   ],
   "source": [
    "#8. Evaluating the Model\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get class with highest score\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "ROzcAT9O2w8o",
    "outputId": "0b3a57c3-3bb2-4ed3-8cb2-4e323a856c8f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnCElEQVR4nO3dfXRU9Z3H8U+IZHhKBkJIJoEQwjMrD24pRMqjEnmwWh7iImpX4lpYNLAiFTTdIqB4stIey2oR6zktlBZ8oIhP21IwQjguCR5QQbCkJA0FShKezEwIJjzkt39wmHVIAtwwwy8J79c59xzm3t/33m9uLvnMnblzJ8wYYwQAwA3WzHYDAICbEwEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQGERmvRokUKCwvTiRMngrbO9PR0denSJWjrawpWrVqlsLAwHTx40D9v1KhRGjVqlLWeLldbj2j4CKAmIiws7JqmrVu3Wu1z1KhR6tu3r9UeQmXr1q1X3PcvvPBCvdbbpUuXgPXExsZq+PDh2rBhQ5B/gtA6c+aMFi1aZP0YrM2Vfm933XWX7faarFtsN4Dg+N3vfhfwePXq1dq8eXON+X369LmRbd1U+vTpU2N/Sxd/N5s2bdKYMWPqve7bbrtNP/7xjyVJR48e1a9+9StNnjxZK1as0MyZM+u93vratGmT45ozZ85o8eLFktSgzp6kmv9/JGnnzp367//+7+v6veHKCKAm4oc//GHA47y8PG3evLnG/MudOXNGrVq1CmVrN424uLha9/fixYvVo0cPDRo0qN7r7tixY8C6H374YXXv3l2/+MUv6gyg8+fPq7q6WhEREfXebl1CsU6bavu9XTqjfeCBByx0dHPgJbibyKWXv3bt2qURI0aoVatW+slPfiLp4ksQixYtqlHTpUsXpaenB8wrKyvTnDlzlJiYKJfLpe7du+vFF19UdXV1UPrcs2eP0tPT1bVrV7Vo0UIej0f/9m//ppMnT9Y6/sSJE5oyZYqioqLUvn17PfHEE6qsrKwx7ve//70GDhyoli1bKjo6WlOnTtXhw4ev2k9xcbH279+vc+fOOf5ZPv30UxUUFOihhx5yXHslHo9Hffr0UVFRkSTp4MGDCgsL089//nMtW7ZM3bp1k8vl0ldffSVJ2r9/v+677z5FR0erRYsW+u53v6v333+/xnr37dunO++8Uy1btlSnTp20ZMmSWn+vtb0HVFlZqUWLFqlnz55q0aKF4uPjNXnyZBUWFurgwYPq0KGDpIuBfOnlrW8fc8Hu0ev1av/+/fJ6vde8Xy+pqqrS+vXrNXLkSHXq1MlxPa4NZ0A3mZMnT2r8+PGaOnWqfvjDHyouLs5R/ZkzZzRy5Ej94x//0L//+7+rc+fO2r59uzIzM1VcXKxly5Zdd4+bN2/W3/72Nz3yyCPyeDzat2+fXn/9de3bt095eXkKCwsLGD9lyhR16dJFWVlZysvL08svv6yvv/5aq1ev9o954YUXtGDBAk2ZMkU/+tGPdPz4cb3yyisaMWKEPv/8c7Vt27bOfjIzM/Xb3/5WRUVFji9QWLNmjSQFPYDOnTunw4cPq3379gHzV65cqcrKSs2YMUMul0vR0dHat2+fhg4dqo4dO+qZZ55R69at9fbbb2vixIlav369Jk2aJEkqKSnRHXfcofPnz/vHvf7662rZsuVV+7lw4YLuueceZWdna+rUqXriiSdUXl6uzZs3a+/evUpNTdWKFSv02GOPadKkSZo8ebIkqX///pIUkh43bNigRx55RCtXrqzxJOpq/vjHP6qsrCzovzdcxqBJysjIMJf/ekeOHGkkmddee63GeElm4cKFNeYnJSWZadOm+R8///zzpnXr1uavf/1rwLhnnnnGhIeHm0OHDl2xr5EjR5pbb731imPOnDlTY94bb7xhJJlt27b55y1cuNBIMj/4wQ8Cxj7++ONGktm9e7cxxpiDBw+a8PBw88ILLwSM+/LLL80tt9wSMH/atGkmKSkpYNy0adOMJFNUVHTFvi93/vx5ExcXZwYPHuyo7nJJSUlmzJgx5vjx4+b48eNm9+7dZurUqUaSmT17tjHGmKKiIiPJREVFmWPHjgXUjx492vTr189UVlb651VXV5vvfe97pkePHv55c+bMMZLMjh07/POOHTtm3G53jZ9/5MiRZuTIkf7Hv/nNb4wk89JLL9Xov7q62hhjzPHjx+s8zkLR48qVK40ks3Llyhrbu5q0tDTjcrnM119/7bgW146X4G4yLpdLjzzySL3r161bp+HDh6tdu3Y6ceKEf0pNTdWFCxe0bdu26+7x289mKysrdeLECd1+++2SpM8++6zG+IyMjIDHs2fPlnTxWawkvfPOO6qurtaUKVMCevZ4POrRo4e2bNlyxX5WrVolY4zjs5/s7GyVlpYG5Vn0pk2b1KFDB3Xo0EEDBgzQunXr9K//+q968cUXA8alpaX5X+qSpFOnTunjjz/WlClTVF5e7v/ZT548qbFjx+rAgQP6xz/+Ieni/rr99ts1ePBgf32HDh2uqf/169crJibGv++/7fIz1suFqsf09HQZYxyf/fh8Pv3P//yP7r777iueGeP68RLcTaZjx47X9QbygQMHtGfPnoA/ct927Nixeq/7klOnTmnx4sV68803a6yvttfze/ToEfC4W7duatasmf8zIQcOHJAxpsa4S5o3b37dPddmzZo1Cg8P1/3333/d60pJSdGSJUsUFhamVq1aqU+fPrX+cUxOTg54XFBQIGOMFixYoAULFtS67mPHjqljx476+9//rpSUlBrLe/XqddX+CgsL1atXL91yi/M/KTeqx2u1fv16VVZW8vLbDUAA3WSu5fX8b7tw4ULA4+rqat11112aP39+reN79uxZ794umTJlirZv36558+bptttuU5s2bVRdXa1x48Zd04UOlz/jrq6uVlhYmP70pz8pPDy8xvg2bdpcd8+X++abb7RhwwalpqY6fp+tNjExMUpNTb3quMt/v5f211NPPaWxY8fWWtO9e/fr7u96NLQe16xZI7fbrXvuueeGbfNmRQBBktSuXTuVlZUFzDt79qyKi4sD5nXr1k2nT5++pj+G9fH1118rOztbixcv1rPPPuuff+DAgTprDhw4EPDMv6CgQNXV1f6XzLp16yZjjJKTk4MSkNfi/fffV3l5ufVn0V27dpV08Szvar+zpKSkWvdzfn7+VbfTrVs37dixQ+fOnavzjLKul+JuVI/Xori4WFu2bFF6erpcLldQ1om68R4QJF38A3L5+zevv/56jTOgKVOmKDc3V3/+859rrKOsrEznz5+/rj4unaEYYwLmX+nquuXLlwc8fuWVVyRJ48ePlyRNnjxZ4eHhWrx4cY31GmPqvLz7kvpchr127Vq1atXKf/WWLbGxsRo1apR+9atf1XgyIUnHjx/3//vuu+9WXl6ePv3004Dll67ku5K0tDSdOHFCv/zlL2ssu7TPL33e7PInOqHqsT6XYb/55puqrq62/sThZsEZECRJP/rRjzRz5kylpaXprrvu0u7du/XnP/9ZMTExAePmzZun999/X/fcc4/S09M1cOBAVVRU6Msvv9Qf/vAHHTx4sEbN5Y4fP64lS5bUmJ+cnKyHHnpII0aM0NKlS3Xu3Dl17NhRmzZt8n/epTZFRUX6wQ9+oHHjxik3N1e///3v9eCDD2rAgAGSLobrkiVLlJmZqYMHD2rixImKjIxUUVGRNmzYoBkzZuipp56qc/1OL8M+deqU/vSnPyktLa3Ol/cOHjyo5ORkTZs2TatWrbrqOq/H8uXLNWzYMPXr10/Tp09X165dVVpaqtzcXB05ckS7d++WJM2fP1+/+93vNG7cOD3xxBP+S5yTkpK0Z8+eK27j4Ycf1urVqzV37lx9+umnGj58uCoqKvTRRx/p8ccf14QJE9SyZUv90z/9k9566y317NlT0dHR6tu3r/r27RuSHutzGfaaNWuUkJDQ4O7U0GTZuvwOoVXXZdh1XQJ94cIF8/TTT5uYmBjTqlUrM3bsWFNQUFDjMmxjjCkvLzeZmZmme/fuJiIiwsTExJjvfe975uc//7k5e/bsFfu6dCl4bdPo0aONMcYcOXLETJo0ybRt29a43W7zL//yL+bo0aM1LuG9dBn2V199Ze677z4TGRlp2rVrZ2bNmmW++eabGttev369GTZsmGndurVp3bq16d27t8nIyDD5+fn+McG4DPu1114zksz7779f55gvv/zSSDLPPPPMVdeXlJRkvv/9719xzKXLsH/2s5/VurywsNA8/PDDxuPxmObNm5uOHTuae+65x/zhD38IGLdnzx4zcuRI06JFC9OxY0fz/PPPm1//+tdXvQzbmIuXz//nf/6nSU5ONs2bNzcej8fcd999prCw0D9m+/btZuDAgSYiIqLG7zPYPTq9DHv//v1Gkpk7d+41jcf1CzPmstckAITcq6++qvnz56uwsDAoFykAjRHvAQEWbNmyRf/xH/9B+OCmxhkQAMAKzoAAAFYQQAAAKwggAIAVBBAAwIoG90HU6upqHT16VJGRkVe9iy4AoOExxqi8vFwJCQlq1qzu85wGF0BHjx5VYmKi7TYAANfp8OHDV/xG2Qb3ElxkZKTtFgAAQXC1v+chC6Dly5erS5cuatGihVJSUgJuHnglvOwGAE3D1f6ehySA3nrrLc2dO1cLFy7UZ599pgEDBmjs2LFB+bIyAEATEYobzA0ePNhkZGT4H1+4cMEkJCSYrKysq9Z6vd46b1bJxMTExNR4Jq/Xe8W/90E/Azp79qx27doV8MVSzZo1U2pqqnJzc2uMr6qqks/nC5gAAE1f0APoxIkTunDhQo2bLMbFxamkpKTG+KysLLndbv/EFXAAcHOwfhVcZmamvF6vfzp8+LDtlgAAN0DQPwcUExOj8PBwlZaWBswvLS2Vx+OpMd7lcvHd6wBwEwr6GVBERIQGDhyo7Oxs/7zq6mplZ2dryJAhwd4cAKCRCsmdEObOnatp06bpu9/9rgYPHqxly5apoqJCjzzySCg2BwBohEISQPfff7+OHz+uZ599ViUlJbrtttu0ceNGvv0RAODX4L4R1efzye12224DAHCdvF6voqKi6lxu/So4AMDNiQACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMCKoAfQokWLFBYWFjD17t072JsBADRyt4Ripbfeeqs++uij/9/ILSHZDACgEQtJMtxyyy3yeDyhWDUAoIkIyXtABw4cUEJCgrp27aqHHnpIhw4dqnNsVVWVfD5fwAQAaPqCHkApKSlatWqVNm7cqBUrVqioqEjDhw9XeXl5reOzsrLkdrv9U2JiYrBbAgA0QGHGGBPKDZSVlSkpKUkvvfSSHn300RrLq6qqVFVV5X/s8/kIIQBoArxer6KioupcHvKrA9q2bauePXuqoKCg1uUul0sulyvUbQAAGpiQfw7o9OnTKiwsVHx8fKg3BQBoRIIeQE899ZRycnJ08OBBbd++XZMmTVJ4eLgeeOCBYG8KANCIBf0luCNHjuiBBx7QyZMn1aFDBw0bNkx5eXnq0KFDsDcFAGjEQn4RglM+n09ut9t2GwCA63S1ixC4FxwAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWBHyL6TDjXXfffc5rpk+fXq9tnX06FHHNZWVlY5r1qxZ47impKTEcY2kOr84EUDwcQYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK8KMMcZ2E9/m8/nkdrttt9Fo/e1vf3Nc06VLl+A3Yll5eXm96vbt2xfkThBsR44ccVyzdOnSem1r586d9arDRV6vV1FRUXUu5wwIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKy4xXYDCK7p06c7runfv3+9tvWXv/zFcU2fPn0c13znO99xXDNq1CjHNZJ0++23O645fPiw45rExETHNTfS+fPnHdccP37ccU18fLzjmvo4dOhQveq4GWlocQYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFZwM9ImJjs7+4bU1NfGjRtvyHbatWtXr7rbbrvNcc2uXbsc1wwaNMhxzY1UWVnpuOavf/2r45r63NA2OjracU1hYaHjGoQeZ0AAACsIIACAFY4DaNu2bbr33nuVkJCgsLAwvfvuuwHLjTF69tlnFR8fr5YtWyo1NVUHDhwIVr8AgCbCcQBVVFRowIABWr58ea3Lly5dqpdfflmvvfaaduzYodatW2vs2LH1ek0ZANB0Ob4IYfz48Ro/fnyty4wxWrZsmX76059qwoQJkqTVq1crLi5O7777rqZOnXp93QIAmoygvgdUVFSkkpISpaam+ue53W6lpKQoNze31pqqqir5fL6ACQDQ9AU1gEpKSiRJcXFxAfPj4uL8yy6XlZUlt9vtnxITE4PZEgCggbJ+FVxmZqa8Xq9/Onz4sO2WAAA3QFADyOPxSJJKS0sD5peWlvqXXc7lcikqKipgAgA0fUENoOTkZHk8noBP1vt8Pu3YsUNDhgwJ5qYAAI2c46vgTp8+rYKCAv/joqIiffHFF4qOjlbnzp01Z84cLVmyRD169FBycrIWLFighIQETZw4MZh9AwAaOccBtHPnTt1xxx3+x3PnzpUkTZs2TatWrdL8+fNVUVGhGTNmqKysTMOGDdPGjRvVokWL4HUNAGj0wowxxnYT3+bz+eR2u223AcChtLQ0xzVvv/2245q9e/c6rvn2k2YnTp06Va86XOT1eq/4vr71q+AAADcnAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArHD8dQwAmr7Y2FjHNa+++qrjmmbNnD8Hfu655xzXcFfrhokzIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwgpuRAqghIyPDcU2HDh0c13z99deOa/Lz8x3XoGHiDAgAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArOBmpEATNnTo0HrVPfPMM0HupHYTJ050XLN3797gNwIrOAMCAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACu4GSnQhN199931qmvevLnjmuzsbMc1ubm5jmvQdHAGBACwggACAFjhOIC2bdume++9VwkJCQoLC9O7774bsDw9PV1hYWEB07hx44LVLwCgiXAcQBUVFRowYICWL19e55hx48apuLjYP73xxhvX1SQAoOlxfBHC+PHjNX78+CuOcblc8ng89W4KAND0heQ9oK1btyo2Nla9evXSY489ppMnT9Y5tqqqSj6fL2ACADR9QQ+gcePGafXq1crOztaLL76onJwcjR8/XhcuXKh1fFZWltxut39KTEwMdksAgAYo6J8Dmjp1qv/f/fr1U//+/dWtWzdt3bpVo0ePrjE+MzNTc+fO9T/2+XyEEADcBEJ+GXbXrl0VExOjgoKCWpe7XC5FRUUFTACApi/kAXTkyBGdPHlS8fHxod4UAKARcfwS3OnTpwPOZoqKivTFF18oOjpa0dHRWrx4sdLS0uTxeFRYWKj58+ere/fuGjt2bFAbBwA0bo4DaOfOnbrjjjv8jy+9fzNt2jStWLFCe/bs0W9/+1uVlZUpISFBY8aM0fPPPy+XyxW8rgEAjV6YMcbYbuLbfD6f3G637TaABqdly5aOaz755JN6bevWW291XHPnnXc6rtm+fbvjGjQeXq/3iu/rcy84AIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWBH0r+QGEBrz5s1zXPPP//zP9drWxo0bHddwZ2s4xRkQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFjBzUgBC77//e87rlmwYIHjGp/P57hGkp577rl61QFOcAYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFZwM1LgOrVv395xzcsvv+y4Jjw83HHNH//4R8c1kpSXl1evOsAJzoAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwApuRgp8S31u+Llx40bHNcnJyY5rCgsLHdcsWLDAcQ1wo3AGBACwggACAFjhKICysrI0aNAgRUZGKjY2VhMnTlR+fn7AmMrKSmVkZKh9+/Zq06aN0tLSVFpaGtSmAQCNn6MAysnJUUZGhvLy8rR582adO3dOY8aMUUVFhX/Mk08+qQ8++EDr1q1TTk6Ojh49qsmTJwe9cQBA4+boIoTL32xdtWqVYmNjtWvXLo0YMUJer1e//vWvtXbtWt15552SpJUrV6pPnz7Ky8vT7bffHrzOAQCN2nW9B+T1eiVJ0dHRkqRdu3bp3LlzSk1N9Y/p3bu3OnfurNzc3FrXUVVVJZ/PFzABAJq+egdQdXW15syZo6FDh6pv376SpJKSEkVERKht27YBY+Pi4lRSUlLrerKysuR2u/1TYmJifVsCADQi9Q6gjIwM7d27V2+++eZ1NZCZmSmv1+ufDh8+fF3rAwA0DvX6IOqsWbP04Ycfatu2berUqZN/vsfj0dmzZ1VWVhZwFlRaWiqPx1Prulwul1wuV33aAAA0Yo7OgIwxmjVrljZs2KCPP/64xqe5Bw4cqObNmys7O9s/Lz8/X4cOHdKQIUOC0zEAoElwdAaUkZGhtWvX6r333lNkZKT/fR23262WLVvK7Xbr0Ucf1dy5cxUdHa2oqCjNnj1bQ4YM4Qo4AEAARwG0YsUKSdKoUaMC5q9cuVLp6emSpF/84hdq1qyZ0tLSVFVVpbFjx+rVV18NSrMAgKYjzBhjbDfxbT6fT26323YbuEn17NnTcc3+/ftD0ElNEyZMcFzzwQcfhKAT4Np4vV5FRUXVuZx7wQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMCKen0jKtDQJSUl1atu06ZNQe6kdvPmzXNc8+GHH4agE8AezoAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwApuRoomacaMGfWq69y5c5A7qV1OTo7jGmNMCDoB7OEMCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCs4GakaPCGDRvmuGb27Nkh6ARAMHEGBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWcDNSNHjDhw93XNOmTZsQdFK7wsJCxzWnT58OQSdA48IZEADACgIIAGCFowDKysrSoEGDFBkZqdjYWE2cOFH5+fkBY0aNGqWwsLCAaebMmUFtGgDQ+DkKoJycHGVkZCgvL0+bN2/WuXPnNGbMGFVUVASMmz59uoqLi/3T0qVLg9o0AKDxc3QRwsaNGwMer1q1SrGxsdq1a5dGjBjhn9+qVSt5PJ7gdAgAaJKu6z0gr9crSYqOjg6Yv2bNGsXExKhv377KzMzUmTNn6lxHVVWVfD5fwAQAaPrqfRl2dXW15syZo6FDh6pv377++Q8++KCSkpKUkJCgPXv26Omnn1Z+fr7eeeedWteTlZWlxYsX17cNAEAjVe8AysjI0N69e/XJJ58EzJ8xY4b/3/369VN8fLxGjx6twsJCdevWrcZ6MjMzNXfuXP9jn8+nxMTE+rYFAGgk6hVAs2bN0ocffqht27apU6dOVxybkpIiSSooKKg1gFwul1wuV33aAAA0Yo4CyBij2bNna8OGDdq6dauSk5OvWvPFF19IkuLj4+vVIACgaXIUQBkZGVq7dq3ee+89RUZGqqSkRJLkdrvVsmVLFRYWau3atbr77rvVvn177dmzR08++aRGjBih/v37h+QHAAA0To4CaMWKFZIuftj021auXKn09HRFREToo48+0rJly1RRUaHExESlpaXppz/9adAaBgA0DY5fgruSxMRE5eTkXFdDAICbA3fDBr5l9+7djmtGjx7tuObUqVOOa4CmhpuRAgCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVYeZqt7i+wXw+n9xut+02AADXyev1Kioqqs7lnAEBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArGlwANbBb0wEA6ulqf88bXACVl5fbbgEAEARX+3ve4O6GXV1draNHjyoyMlJhYWEBy3w+nxITE3X48OEr3mG1qWM/XMR+uIj9cBH74aKGsB+MMSovL1dCQoKaNav7POeWG9jTNWnWrJk6dep0xTFRUVE39QF2CfvhIvbDReyHi9gPF9neD9fytToN7iU4AMDNgQACAFjRqALI5XJp4cKFcrlctluxiv1wEfvhIvbDReyHixrTfmhwFyEAAG4OjeoMCADQdBBAAAArCCAAgBUEEADACgIIAGBFowmg5cuXq0uXLmrRooVSUlL06aef2m7phlu0aJHCwsICpt69e9tuK+S2bdume++9VwkJCQoLC9O7774bsNwYo2effVbx8fFq2bKlUlNTdeDAATvNhtDV9kN6enqN42PcuHF2mg2RrKwsDRo0SJGRkYqNjdXEiROVn58fMKayslIZGRlq37692rRpo7S0NJWWllrqODSuZT+MGjWqxvEwc+ZMSx3XrlEE0FtvvaW5c+dq4cKF+uyzzzRgwACNHTtWx44ds93aDXfrrbequLjYP33yySe2Wwq5iooKDRgwQMuXL691+dKlS/Xyyy/rtdde044dO9S6dWuNHTtWlZWVN7jT0LrafpCkcePGBRwfb7zxxg3sMPRycnKUkZGhvLw8bd68WefOndOYMWNUUVHhH/Pkk0/qgw8+0Lp165STk6OjR49q8uTJFrsOvmvZD5I0ffr0gONh6dKlljqug2kEBg8ebDIyMvyPL1y4YBISEkxWVpbFrm68hQsXmgEDBthuwypJZsOGDf7H1dXVxuPxmJ/97Gf+eWVlZcblcpk33njDQoc3xuX7wRhjpk2bZiZMmGClH1uOHTtmJJmcnBxjzMXfffPmzc26dev8Y/7yl78YSSY3N9dWmyF3+X4wxpiRI0eaJ554wl5T16DBnwGdPXtWu3btUmpqqn9es2bNlJqaqtzcXIud2XHgwAElJCSoa9eueuihh3To0CHbLVlVVFSkkpKSgOPD7XYrJSXlpjw+tm7dqtjYWPXq1UuPPfaYTp48abulkPJ6vZKk6OhoSdKuXbt07ty5gOOhd+/e6ty5c5M+Hi7fD5esWbNGMTEx6tu3rzIzM3XmzBkb7dWpwd0N+3InTpzQhQsXFBcXFzA/Li5O+/fvt9SVHSkpKVq1apV69eql4uJiLV68WMOHD9fevXsVGRlpuz0rSkpKJKnW4+PSspvFuHHjNHnyZCUnJ6uwsFA/+clPNH78eOXm5io8PNx2e0FXXV2tOXPmaOjQoerbt6+ki8dDRESE2rZtGzC2KR8Pte0HSXrwwQeVlJSkhIQE7dmzR08//bTy8/P1zjvvWOw2UIMPIPy/8ePH+//dv39/paSkKCkpSW+//bYeffRRi52hIZg6dar/3/369VP//v3VrVs3bd26VaNHj7bYWWhkZGRo7969N8X7oFdS136YMWOG/9/9+vVTfHy8Ro8ercLCQnXr1u1Gt1mrBv8SXExMjMLDw2tcxVJaWiqPx2Opq4ahbdu26tmzpwoKCmy3Ys2lY4Djo6auXbsqJiamSR4fs2bN0ocffqgtW7YEfH+Yx+PR2bNnVVZWFjC+qR4Pde2H2qSkpEhSgzoeGnwARUREaODAgcrOzvbPq66uVnZ2toYMGWKxM/tOnz6twsJCxcfH227FmuTkZHk8noDjw+fzaceOHTf98XHkyBGdPHmySR0fxhjNmjVLGzZs0Mcff6zk5OSA5QMHDlTz5s0Djof8/HwdOnSoSR0PV9sPtfniiy8kqWEdD7avgrgWb775pnG5XGbVqlXmq6++MjNmzDBt27Y1JSUltlu7oX784x+brVu3mqKiIvO///u/JjU11cTExJhjx47Zbi2kysvLzeeff24+//xzI8m89NJL5vPPPzd///vfjTHG/Nd//Zdp27atee+998yePXvMhAkTTHJysvnmm28sdx5cV9oP5eXl5qmnnjK5ubmmqKjIfPTRR+Y73/mO6dGjh6msrLTdetA89thjxu12m61bt5ri4mL/dObMGf+YmTNnms6dO5uPP/7Y7Ny50wwZMsQMGTLEYtfBd7X9UFBQYJ577jmzc+dOU1RUZN577z3TtWtXM2LECMudB2oUAWSMMa+88orp3LmziYiIMIMHDzZ5eXm2W7rh7r//fhMfH28iIiJMx44dzf33328KCgpstxVyW7ZsMZJqTNOmTTPGXLwUe8GCBSYuLs64XC4zevRok5+fb7fpELjSfjhz5owZM2aM6dChg2nevLlJSkoy06dPb3JP0mr7+SWZlStX+sd888035vHHHzft2rUzrVq1MpMmTTLFxcX2mg6Bq+2HQ4cOmREjRpjo6GjjcrlM9+7dzbx584zX67Xb+GX4PiAAgBUN/j0gAEDTRAABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVvwf/gnucVsAurgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#9. Visualizing Results\n",
    "\n",
    "# Display a sample image and prediction\n",
    "import numpy as np\n",
    "\n",
    "sample_image, sample_label = next(iter(test_loader))\n",
    "sample_image = sample_image[0].to(device)\n",
    "sample_label = sample_label[0].item()\n",
    "\n",
    "output = model(sample_image.unsqueeze(0))\n",
    "_, predicted_label = torch.max(output.data, 1)\n",
    "\n",
    "plt.imshow(sample_image.cpu().squeeze(), cmap='gray')\n",
    "plt.title(f\"True Label: {sample_label}, Predicted: {predicted_label.item()}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xv8QsuCZ23-j"
   },
   "source": [
    "**10. Summary of Workflow\n",
    "\n",
    "1. Preprocessing: Load and normalize data.\n",
    "\n",
    "\n",
    "2. Model Architecture: Define a CNN with convolutional, pooling, and fully connected layers.\n",
    "\n",
    "\n",
    "3. Training: Use the loss function and optimizer to update weights.\n",
    "\n",
    "\n",
    "4. Evaluation: Measure performance on test data.\n",
    "\n",
    "\n",
    "5. Visualization: Inspect predictions for sample inputs.\n",
    "\n",
    "\n",
    "\n",
    "**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
